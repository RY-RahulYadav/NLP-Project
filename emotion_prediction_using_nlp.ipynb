{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "UtqvXZc_8ije"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0MEuLpJK8oLy"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Emotion_Data.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "ffarDqDs9bBb",
    "outputId": "afc8b890-fe13-454a-b08b-b1d2535d573a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>i feel wimpy for complaining about taking cred...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>i feel so peaceful so i know i made the right ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "      <td>i really feel like i m wading in dangerous wat...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>i feel like i cant take it anymore i told my b...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>i have already said i am one of many feeling t...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2472</th>\n",
       "      <td>i was feeling pretty well in mid october</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4597</th>\n",
       "      <td>i am feeling anxious that im not out watching ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>the possibility of having failed the examination</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>i dont really connect with the main character ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>i dont want to pretend i am someone and i am n...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Comment Emotion\n",
       "1979  i feel wimpy for complaining about taking cred...    fear\n",
       "623   i feel so peaceful so i know i made the right ...     joy\n",
       "2364  i really feel like i m wading in dangerous wat...   anger\n",
       "602   i feel like i cant take it anymore i told my b...   anger\n",
       "2356  i have already said i am one of many feeling t...    fear\n",
       "2472           i was feeling pretty well in mid october     joy\n",
       "4597  i am feeling anxious that im not out watching ...    fear\n",
       "93     the possibility of having failed the examination    fear\n",
       "2736  i dont really connect with the main character ...     joy\n",
       "5561  i dont want to pretend i am someone and i am n...     joy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEntMWbl9icx",
    "outputId": "7352c968-aeba-4511-d045-21947ab537c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotion\n",
       "anger    2000\n",
       "joy      2000\n",
       "fear     1937\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_sCK7xn-Fmj",
    "outputId": "0c9d6301-8cd4-4a34-a8ef-223a17830f9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comment    0\n",
       "Emotion    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "WI6d5NH1-kSY",
    "outputId": "b4e99dae-0534-4ddd-d1d0-420fc7cdec67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1937.,    0.,    0.,    0.,    0., 2000.,    0.,    0.,    0.,\n",
       "        2000.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0cAAAFfCAYAAACFoLdcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAArdUlEQVR4nO3de3RV9Zn/8ffhcoJBEgyY2xgDakVBQEHFVKUwIBEj3tBRRMEaQZ2glVSl6c9iwNYwYPHK6GhFtIWCdqxWUCRABQoREVfkplnCYIMjCY5KToExIeT8/pjFrqeAkJgYwPdrrb1W9vf77L2fbbv28uO+nFA0Go0iSZIkSd9zLZq7AUmSJEk6HBiOJEmSJAnDkSRJkiQBhiNJkiRJAgxHkiRJkgQYjiRJkiQJMBxJkiRJEgCtmruBplJXV8enn35Ku3btCIVCzd2OJEmSpGYSjUb529/+Rnp6Oi1aHPj+0FEbjj799FMyMjKauw1JkiRJh4ktW7ZwwgknHHD+qA1H7dq1A/7vH0BCQkIzdyNJkiSpuUQiETIyMoKMcCBHbTja+yhdQkKC4UiSJEnSQV+38YMMkiRJkoThSJIkSZIAw5EkSZIkAYYjSZIkSQIMR5IkSZIEGI4kSZIkCTAcSZIkSRJgOJIkSZIkoJ7hqKioiHPOOYd27dqRnJzMFVdcQVlZWUzNV199RV5eHh06dODYY49l6NChVFZWxtSUl5eTk5NDfHw8ycnJ3HPPPdTW1sbUvPXWW/Tq1Yu4uDhOOeUUZsyY0bAzlCRJkqRDUK9wtGTJEvLy8nj77bcpLi5m9+7dDBo0iJ07dwY1Y8eO5bXXXuOll15iyZIlfPrpp1x11VXB/J49e8jJyaGmpoYVK1bw/PPPM2PGDMaPHx/UbN68mZycHPr3709paSl33XUXt9xyC2+++WYjnLIkSZIk7SsUjUajDd34s88+Izk5mSVLltC3b1+qqqo4/vjjmTVrFldffTUAH374IaeffjolJSWcd955vPHGG1x66aV8+umnpKSkAPDUU08xbtw4PvvsM8LhMOPGjWPevHmsW7cuONZ1113H9u3bmT9//iH1FolESExMpKqqioSEhIaeoiRJkqQj3KFmg2/1zlFVVRUASUlJAKxevZrdu3czcODAoOa0007jxBNPpKSkBICSkhK6d+8eBCOA7OxsIpEI69evD2q+vo+9NXv3sT/V1dVEIpGYRZIkSZIOVauGblhXV8ddd93F+eefzxlnnAFARUUF4XCY9u3bx9SmpKRQUVER1Hw9GO2d3zv3TTWRSIT//d//5Zhjjtmnn6KiIiZMmNDQ05EkHaU6/Wxec7dw2Pp4Uk5ztyAdFbzOHNiRdp1p8J2jvLw81q1bx+zZsxuznwYrKCigqqoqWLZs2dLcLUmSJEk6gjToztGYMWOYO3cuS5cu5YQTTgjGU1NTqampYfv27TF3jyorK0lNTQ1q3nnnnZj97f2a3ddr/vELd5WVlSQkJOz3rhFAXFwccXFxDTkdSZIkSarfnaNoNMqYMWP44x//yOLFi+ncuXPMfO/evWndujWLFi0KxsrKyigvLycrKwuArKws1q5dy7Zt24Ka4uJiEhIS6Nq1a1Dz9X3srdm7D0mSJElqbPW6c5SXl8esWbN49dVXadeuXfCOUGJiIscccwyJiYnk5uaSn59PUlISCQkJ3HHHHWRlZXHeeecBMGjQILp27cqNN97I5MmTqaio4L777iMvLy+483PbbbfxxBNPcO+993LzzTezePFiXnzxRebN83lOSZIkSU2jXneOnnzySaqqqujXrx9paWnBMmfOnKDm4Ycf5tJLL2Xo0KH07duX1NRUXn755WC+ZcuWzJ07l5YtW5KVlcUNN9zAiBEjmDhxYlDTuXNn5s2bR3FxMT179uTXv/41v/nNb8jOzm6EU5YkSZKkfX2r3zk6nPk7R5Ik8CtS3+RI+4qUdLjyOnNgh8t15jv5nSNJkiRJOloYjiRJkiSJb/EjsKofb7ce2OFyu1WSJEnfb945kiRJkiQMR5IkSZIEGI4kSZIkCTAcSZIkSRJgOJIkSZIkwHAkSZIkSYDhSJIkSZIAw5EkSZIkAYYjSZIkSQIMR5IkSZIEGI4kSZIkCTAcSZIkSRJgOJIkSZIkwHAkSZIkSYDhSJIkSZIAw5EkSZIkAYYjSZIkSQIMR5IkSZIEGI4kSZIkCTAcSZIkSRJgOJIkSZIkwHAkSZIkSYDhSJIkSZKABoSjpUuXMmTIENLT0wmFQrzyyisx86FQaL/LlClTgppOnTrtMz9p0qSY/axZs4YLL7yQNm3akJGRweTJkxt2hpIkSZJ0COodjnbu3EnPnj2ZNm3afue3bt0as0yfPp1QKMTQoUNj6iZOnBhTd8cddwRzkUiEQYMGkZmZyerVq5kyZQqFhYU8/fTT9W1XkiRJkg5Jq/puMHjwYAYPHnzA+dTU1Jj1V199lf79+3PSSSfFjLdr126f2r1mzpxJTU0N06dPJxwO061bN0pLS5k6dSqjR4+ub8uSJEmSdFBN+s5RZWUl8+bNIzc3d5+5SZMm0aFDB8466yymTJlCbW1tMFdSUkLfvn0Jh8PBWHZ2NmVlZXz55Zf7PVZ1dTWRSCRmkSRJkqRDVe87R/Xx/PPP065dO6666qqY8TvvvJNevXqRlJTEihUrKCgoYOvWrUydOhWAiooKOnfuHLNNSkpKMHfcccftc6yioiImTJjQRGciSZIk6WjXpOFo+vTpDB8+nDZt2sSM5+fnB3/36NGDcDjMrbfeSlFREXFxcQ06VkFBQcx+I5EIGRkZDWtckiRJ0vdOk4WjZcuWUVZWxpw5cw5a26dPH2pra/n444/p0qULqampVFZWxtTsXT/Qe0pxcXENDlaSJEmS1GTvHD377LP07t2bnj17HrS2tLSUFi1akJycDEBWVhZLly5l9+7dQU1xcTFdunTZ7yN1kiRJkvRt1Tsc7dixg9LSUkpLSwHYvHkzpaWllJeXBzWRSISXXnqJW265ZZ/tS0pKeOSRR3j//ff5r//6L2bOnMnYsWO54YYbguBz/fXXEw6Hyc3NZf369cyZM4dHH3005rE5SZIkSWpM9X6s7t1336V///7B+t7AMnLkSGbMmAHA7NmziUajDBs2bJ/t4+LimD17NoWFhVRXV9O5c2fGjh0bE3wSExNZsGABeXl59O7dm44dOzJ+/Hg/4y1JkiSpydQ7HPXr149oNPqNNaNHjz5gkOnVqxdvv/32QY/To0cPli1bVt/2JEmSJKlBmvR3jiRJkiTpSGE4kiRJkiQMR5IkSZIEGI4kSZIkCTAcSZIkSRJgOJIkSZIkwHAkSZIkSYDhSJIkSZIAw5EkSZIkAYYjSZIkSQIMR5IkSZIEGI4kSZIkCTAcSZIkSRJgOJIkSZIkwHAkSZIkSYDhSJIkSZIAw5EkSZIkAYYjSZIkSQIMR5IkSZIEGI4kSZIkCTAcSZIkSRJgOJIkSZIkwHAkSZIkSYDhSJIkSZIAw5EkSZIkAYYjSZIkSQIaEI6WLl3KkCFDSE9PJxQK8corr8TM33TTTYRCoZjl4osvjqn54osvGD58OAkJCbRv357c3Fx27NgRU7NmzRouvPBC2rRpQ0ZGBpMnT67/2UmSJEnSIap3ONq5cyc9e/Zk2rRpB6y5+OKL2bp1a7D8/ve/j5kfPnw469evp7i4mLlz57J06VJGjx4dzEciEQYNGkRmZiarV69mypQpFBYW8vTTT9e3XUmSJEk6JK3qu8HgwYMZPHjwN9bExcWRmpq637kPPviA+fPns2rVKs4++2wAHn/8cS655BIeeugh0tPTmTlzJjU1NUyfPp1wOEy3bt0oLS1l6tSpMSHq66qrq6murg7WI5FIfU9NkiRJ0vdYk7xz9NZbb5GcnEyXLl24/fbb+fzzz4O5kpIS2rdvHwQjgIEDB9KiRQtWrlwZ1PTt25dwOBzUZGdnU1ZWxpdffrnfYxYVFZGYmBgsGRkZTXFqkiRJko5SjR6OLr74Yl544QUWLVrEv/3bv7FkyRIGDx7Mnj17AKioqCA5OTlmm1atWpGUlERFRUVQk5KSElOzd31vzT8qKCigqqoqWLZs2dLYpyZJkiTpKFbvx+oO5rrrrgv+7t69Oz169ODkk0/mrbfeYsCAAY19uEBcXBxxcXFNtn9JkiRJR7cm/5T3SSedRMeOHdm4cSMAqampbNu2LaamtraWL774InhPKTU1lcrKypiavesHepdJkiRJkr6NJg9Hn3zyCZ9//jlpaWkAZGVlsX37dlavXh3ULF68mLq6Ovr06RPULF26lN27dwc1xcXFdOnSheOOO66pW5YkSZL0PVTvcLRjxw5KS0spLS0FYPPmzZSWllJeXs6OHTu45557ePvtt/n4449ZtGgRl19+OaeccgrZ2dkAnH766Vx88cWMGjWKd955h+XLlzNmzBiuu+460tPTAbj++usJh8Pk5uayfv165syZw6OPPkp+fn7jnbkkSZIkfU29w9G7777LWWedxVlnnQVAfn4+Z511FuPHj6dly5asWbOGyy67jFNPPZXc3Fx69+7NsmXLYt4HmjlzJqeddhoDBgzgkksu4YILLoj5DaPExEQWLFjA5s2b6d27Nz/96U8ZP378AT/jLUmSJEnfVr0/yNCvXz+i0egB5998882D7iMpKYlZs2Z9Y02PHj1YtmxZfduTJEmSpAZp8neOJEmSJOlIYDiSJEmSJAxHkiRJkgQYjiRJkiQJMBxJkiRJEmA4kiRJkiTAcCRJkiRJgOFIkiRJkgDDkSRJkiQBhiNJkiRJAgxHkiRJkgQYjiRJkiQJMBxJkiRJEmA4kiRJkiTAcCRJkiRJgOFIkiRJkgDDkSRJkiQBhiNJkiRJAgxHkiRJkgQYjiRJkiQJMBxJkiRJEmA4kiRJkiTAcCRJkiRJgOFIkiRJkgDDkSRJkiQBDQhHS5cuZciQIaSnpxMKhXjllVeCud27dzNu3Di6d+9O27ZtSU9PZ8SIEXz66acx++jUqROhUChmmTRpUkzNmjVruPDCC2nTpg0ZGRlMnjy5YWcoSZIkSYeg3uFo586d9OzZk2nTpu0zt2vXLt577z1+8Ytf8N577/Hyyy9TVlbGZZddtk/txIkT2bp1a7DccccdwVwkEmHQoEFkZmayevVqpkyZQmFhIU8//XR925UkSZKkQ9KqvhsMHjyYwYMH73cuMTGR4uLimLEnnniCc889l/Lyck488cRgvF27dqSmpu53PzNnzqSmpobp06cTDofp1q0bpaWlTJ06ldGjR9e3ZUmSJEk6qCZ/56iqqopQKET79u1jxidNmkSHDh0466yzmDJlCrW1tcFcSUkJffv2JRwOB2PZ2dmUlZXx5Zdf7vc41dXVRCKRmEWSJEmSDlW97xzVx1dffcW4ceMYNmwYCQkJwfidd95Jr169SEpKYsWKFRQUFLB161amTp0KQEVFBZ07d47ZV0pKSjB33HHH7XOsoqIiJkyY0IRnI0mSJOlo1mThaPfu3fzLv/wL0WiUJ598MmYuPz8/+LtHjx6Ew2FuvfVWioqKiIuLa9DxCgoKYvYbiUTIyMhoWPOSJEmSvneaJBztDUZ//etfWbx4ccxdo/3p06cPtbW1fPzxx3Tp0oXU1FQqKytjavauH+g9pbi4uAYHK0mSJElq9HeO9gajjz76iIULF9KhQ4eDblNaWkqLFi1ITk4GICsri6VLl7J79+6gpri4mC5duuz3kTpJkiRJ+rbqfedox44dbNy4MVjfvHkzpaWlJCUlkZaWxtVXX817773H3Llz2bNnDxUVFQAkJSURDocpKSlh5cqV9O/fn3bt2lFSUsLYsWO54YYbguBz/fXXM2HCBHJzcxk3bhzr1q3j0Ucf5eGHH26k05YkSZKkWPUOR++++y79+/cP1ve+5zNy5EgKCwv505/+BMCZZ54Zs92f//xn+vXrR1xcHLNnz6awsJDq6mo6d+7M2LFjY94XSkxMZMGCBeTl5dG7d286duzI+PHj/Yy3JEmSpCZT73DUr18/otHoAee/aQ6gV69evP322wc9To8ePVi2bFl925MkSZKkBmny3zmSJEmSpCOB4UiSJEmSMBxJkiRJEmA4kiRJkiTAcCRJkiRJgOFIkiRJkgDDkSRJkiQBhiNJkiRJAgxHkiRJkgQYjiRJkiQJMBxJkiRJEmA4kiRJkiTAcCRJkiRJgOFIkiRJkgDDkSRJkiQBhiNJkiRJAgxHkiRJkgQYjiRJkiQJMBxJkiRJEmA4kiRJkiTAcCRJkiRJgOFIkiRJkgDDkSRJkiQBhiNJkiRJAgxHkiRJkgQYjiRJkiQJaEA4Wrp0KUOGDCE9PZ1QKMQrr7wSMx+NRhk/fjxpaWkcc8wxDBw4kI8++iim5osvvmD48OEkJCTQvn17cnNz2bFjR0zNmjVruPDCC2nTpg0ZGRlMnjy5/mcnSZIkSYeo3uFo586d9OzZk2nTpu13fvLkyTz22GM89dRTrFy5krZt25Kdnc1XX30V1AwfPpz169dTXFzM3LlzWbp0KaNHjw7mI5EIgwYNIjMzk9WrVzNlyhQKCwt5+umnG3CKkiRJknRwreq7weDBgxk8ePB+56LRKI888gj33Xcfl19+OQAvvPACKSkpvPLKK1x33XV88MEHzJ8/n1WrVnH22WcD8Pjjj3PJJZfw0EMPkZ6ezsyZM6mpqWH69OmEw2G6detGaWkpU6dOjQlRkiRJktRYGvWdo82bN1NRUcHAgQODscTERPr06UNJSQkAJSUltG/fPghGAAMHDqRFixasXLkyqOnbty/hcDioyc7OpqysjC+//HK/x66uriYSicQskiRJknSoGjUcVVRUAJCSkhIznpKSEsxVVFSQnJwcM9+qVSuSkpJiava3j68f4x8VFRWRmJgYLBkZGd/+hCRJkiR9bxw1X6srKCigqqoqWLZs2dLcLUmSJEk6gjRqOEpNTQWgsrIyZryysjKYS01NZdu2bTHztbW1fPHFFzE1+9vH14/xj+Li4khISIhZJEmSJOlQNWo46ty5M6mpqSxatCgYi0QirFy5kqysLACysrLYvn07q1evDmoWL15MXV0dffr0CWqWLl3K7t27g5ri4mK6dOnCcccd15gtS5IkSRLQgHC0Y8cOSktLKS0tBf7vIwylpaWUl5cTCoW46667+OUvf8mf/vQn1q5dy4gRI0hPT+eKK64A4PTTT+fiiy9m1KhRvPPOOyxfvpwxY8Zw3XXXkZ6eDsD1119POBwmNzeX9evXM2fOHB599FHy8/Mb7cQlSZIk6evq/Snvd999l/79+wfrewPLyJEjmTFjBvfeey87d+5k9OjRbN++nQsuuID58+fTpk2bYJuZM2cyZswYBgwYQIsWLRg6dCiPPfZYMJ+YmMiCBQvIy8ujd+/edOzYkfHjx/sZb0mSJElNpt7hqF+/fkSj0QPOh0IhJk6cyMSJEw9Yk5SUxKxZs77xOD169GDZsmX1bU+SJEmSGuSo+VqdJEmSJH0bhiNJkiRJwnAkSZIkSYDhSJIkSZIAw5EkSZIkAYYjSZIkSQIMR5IkSZIEGI4kSZIkCTAcSZIkSRJgOJIkSZIkwHAkSZIkSYDhSJIkSZIAw5EkSZIkAYYjSZIkSQIMR5IkSZIEGI4kSZIkCTAcSZIkSRJgOJIkSZIkwHAkSZIkSYDhSJIkSZIAw5EkSZIkAYYjSZIkSQIMR5IkSZIEGI4kSZIkCTAcSZIkSRJgOJIkSZIkoAnCUadOnQiFQvsseXl5APTr12+fudtuuy1mH+Xl5eTk5BAfH09ycjL33HMPtbW1jd2qJEmSJAVaNfYOV61axZ49e4L1devWcdFFF3HNNdcEY6NGjWLixInBenx8fPD3nj17yMnJITU1lRUrVrB161ZGjBhB69atefDBBxu7XUmSJEkCmiAcHX/88THrkyZN4uSTT+ZHP/pRMBYfH09qaup+t1+wYAEbNmxg4cKFpKSkcOaZZ/LAAw8wbtw4CgsLCYfD+92uurqa6urqYD0SiTTC2UiSJEn6vmjSd45qamr43e9+x80330woFArGZ86cSceOHTnjjDMoKChg165dwVxJSQndu3cnJSUlGMvOziYSibB+/foDHquoqIjExMRgycjIaJqTkiRJknRUavQ7R1/3yiuvsH37dm666aZg7PrrryczM5P09HTWrFnDuHHjKCsr4+WXXwagoqIiJhgBwXpFRcUBj1VQUEB+fn6wHolEDEiSJEmSDlmThqNnn32WwYMHk56eHoyNHj06+Lt79+6kpaUxYMAANm3axMknn9zgY8XFxREXF/et+pUkSZL0/dVkj9X99a9/ZeHChdxyyy3fWNenTx8ANm7cCEBqaiqVlZUxNXvXD/SekiRJkiR9W00Wjp577jmSk5PJycn5xrrS0lIA0tLSAMjKymLt2rVs27YtqCkuLiYhIYGuXbs2VbuSJEmSvuea5LG6uro6nnvuOUaOHEmrVn8/xKZNm5g1axaXXHIJHTp0YM2aNYwdO5a+ffvSo0cPAAYNGkTXrl258cYbmTx5MhUVFdx3333k5eX52JwkSZKkJtMk4WjhwoWUl5dz8803x4yHw2EWLlzII488ws6dO8nIyGDo0KHcd999QU3Lli2ZO3cut99+O1lZWbRt25aRI0fG/C6SJEmSJDW2JglHgwYNIhqN7jOekZHBkiVLDrp9ZmYmr7/+elO0JkmSJEn71aS/cyRJkiRJRwrDkSRJkiRhOJIkSZIkwHAkSZIkSYDhSJIkSZIAw5EkSZIkAYYjSZIkSQIMR5IkSZIEGI4kSZIkCTAcSZIkSRJgOJIkSZIkwHAkSZIkSYDhSJIkSZIAw5EkSZIkAYYjSZIkSQIMR5IkSZIEGI4kSZIkCTAcSZIkSRJgOJIkSZIkwHAkSZIkSYDhSJIkSZIAw5EkSZIkAYYjSZIkSQIMR5IkSZIEGI4kSZIkCWiCcFRYWEgoFIpZTjvttGD+q6++Ii8vjw4dOnDssccydOhQKisrY/ZRXl5OTk4O8fHxJCcnc88991BbW9vYrUqSJElSoFVT7LRbt24sXLjw7wdp9ffDjB07lnnz5vHSSy+RmJjImDFjuOqqq1i+fDkAe/bsIScnh9TUVFasWMHWrVsZMWIErVu35sEHH2yKdiVJkiSpacJRq1atSE1N3We8qqqKZ599llmzZvHP//zPADz33HOcfvrpvP3225x33nksWLCADRs2sHDhQlJSUjjzzDN54IEHGDduHIWFhYTD4aZoWZIkSdL3XJO8c/TRRx+Rnp7OSSedxPDhwykvLwdg9erV7N69m4EDBwa1p512GieeeCIlJSUAlJSU0L17d1JSUoKa7OxsIpEI69evP+Axq6uriUQiMYskSZIkHapGD0d9+vRhxowZzJ8/nyeffJLNmzdz4YUX8re//Y2KigrC4TDt27eP2SYlJYWKigoAKioqYoLR3vm9cwdSVFREYmJisGRkZDTuiUmSJEk6qjX6Y3WDBw8O/u7Rowd9+vQhMzOTF198kWOOOaaxDxcoKCggPz8/WI9EIgYkSZIkSYesyT/l3b59e0499VQ2btxIamoqNTU1bN++PaamsrIyeEcpNTV1n6/X7V3f33tMe8XFxZGQkBCzSJIkSdKhavJwtGPHDjZt2kRaWhq9e/emdevWLFq0KJgvKyujvLycrKwsALKysli7di3btm0LaoqLi0lISKBr165N3a4kSZKk76lGf6zu7rvvZsiQIWRmZvLpp59y//3307JlS4YNG0ZiYiK5ubnk5+eTlJREQkICd9xxB1lZWZx33nkADBo0iK5du3LjjTcyefJkKioquO+++8jLyyMuLq6x25UkSZIkoAnC0SeffMKwYcP4/PPPOf7447ngggt4++23Of744wF4+OGHadGiBUOHDqW6uprs7Gz+/d//Pdi+ZcuWzJ07l9tvv52srCzatm3LyJEjmThxYmO3KkmSJEmBRg9Hs2fP/sb5Nm3aMG3aNKZNm3bAmszMTF5//fXGbk2SJEmSDqjJ3zmSJEmSpCOB4UiSJEmSMBxJkiRJEmA4kiRJkiTAcCRJkiRJgOFIkiRJkgDDkSRJkiQBhiNJkiRJAgxHkiRJkgQYjiRJkiQJMBxJkiRJEmA4kiRJkiTAcCRJkiRJgOFIkiRJkgDDkSRJkiQBhiNJkiRJAgxHkiRJkgQYjiRJkiQJMBxJkiRJEmA4kiRJkiTAcCRJkiRJgOFIkiRJkgDDkSRJkiQBhiNJkiRJAgxHkiRJkgQYjiRJkiQJaIJwVFRUxDnnnEO7du1ITk7miiuuoKysLKamX79+hEKhmOW2226LqSkvLycnJ4f4+HiSk5O55557qK2tbex2JUmSJAmAVo29wyVLlpCXl8c555xDbW0tP//5zxk0aBAbNmygbdu2Qd2oUaOYOHFisB4fHx/8vWfPHnJyckhNTWXFihVs3bqVESNG0Lp1ax588MHGblmSJEmSGj8czZ8/P2Z9xowZJCcns3r1avr27RuMx8fHk5qaut99LFiwgA0bNrBw4UJSUlI488wzeeCBBxg3bhyFhYWEw+HGbluSJEnS91yTv3NUVVUFQFJSUsz4zJkz6dixI2eccQYFBQXs2rUrmCspKaF79+6kpKQEY9nZ2UQiEdavX7/f41RXVxOJRGIWSZIkSTpUjX7n6Ovq6uq46667OP/88znjjDOC8euvv57MzEzS09NZs2YN48aNo6ysjJdffhmAioqKmGAEBOsVFRX7PVZRURETJkxoojORJEmSdLRr0nCUl5fHunXr+Mtf/hIzPnr06ODv7t27k5aWxoABA9i0aRMnn3xyg45VUFBAfn5+sB6JRMjIyGhY45IkSZK+d5rssboxY8Ywd+5c/vznP3PCCSd8Y22fPn0A2LhxIwCpqalUVlbG1OxdP9B7SnFxcSQkJMQskiRJknSoGj0cRaNRxowZwx//+EcWL15M586dD7pNaWkpAGlpaQBkZWWxdu1atm3bFtQUFxeTkJBA165dG7tlSZIkSWr8x+ry8vKYNWsWr776Ku3atQveEUpMTOSYY45h06ZNzJo1i0suuYQOHTqwZs0axo4dS9++fenRowcAgwYNomvXrtx4441MnjyZiooK7rvvPvLy8oiLi2vsliVJkiSp8e8cPfnkk1RVVdGvXz/S0tKCZc6cOQCEw2EWLlzIoEGDOO200/jpT3/K0KFDee2114J9tGzZkrlz59KyZUuysrK44YYbGDFiRMzvIkmSJElSY2r0O0fRaPQb5zMyMliyZMlB95OZmcnrr7/eWG1JkiRJ0jdq8t85kiRJkqQjgeFIkiRJkjAcSZIkSRJgOJIkSZIkwHAkSZIkSYDhSJIkSZIAw5EkSZIkAYYjSZIkSQIMR5IkSZIEGI4kSZIkCTAcSZIkSRJgOJIkSZIkwHAkSZIkSYDhSJIkSZIAw5EkSZIkAYYjSZIkSQIMR5IkSZIEGI4kSZIkCTAcSZIkSRJgOJIkSZIkwHAkSZIkSYDhSJIkSZIAw5EkSZIkAYYjSZIkSQIMR5IkSZIEGI4kSZIkCTjMw9G0adPo1KkTbdq0oU+fPrzzzjvN3ZIkSZKko9RhG47mzJlDfn4+999/P++99x49e/YkOzubbdu2NXdrkiRJko5CrZq7gQOZOnUqo0aN4sc//jEATz31FPPmzWP69On87Gc/26e+urqa6urqYL2qqgqASCTy3TR8EHXVu5q7hcPW4fK/kaSjk9ffA/P6KzUOrzMHdrhcZ/b2EY1Gv7EuFD1YRTOoqakhPj6eP/zhD1xxxRXB+MiRI9m+fTuvvvrqPtsUFhYyYcKE77BLSZIkSUeSLVu2cMIJJxxw/rC8c/Q///M/7Nmzh5SUlJjxlJQUPvzww/1uU1BQQH5+frBeV1fHF198QYcOHQiFQk3a78FEIhEyMjLYsmULCQkJzdqLJH2feP2VpOZzOF2Do9Eof/vb30hPT//GusMyHDVEXFwccXFxMWPt27dvnmYOICEhodn/jyFJ30defyWp+Rwu1+DExMSD1hyWH2To2LEjLVu2pLKyMma8srKS1NTUZupKkiRJ0tHssAxH4XCY3r17s2jRomCsrq6ORYsWkZWV1YydSZIkSTpaHbaP1eXn5zNy5EjOPvtszj33XB555BF27twZfL3uSBIXF8f999+/z2N/kqSm5fVXkprPkXgNPiy/VrfXE088wZQpU6ioqODMM8/kscceo0+fPs3dliRJkqSj0GEdjiRJkiTpu3JYvnMkSZIkSd81w5EkSZIkYTiSJEmSJMBw1GDRaJTRo0eTlJREKBSitLS0uVuSJEmSvjM33XQTV1xxRXO30aj8IEMDvfHGG1x++eW89dZbnHTSSXTs2JFWrQ7bL6NLkiRJjaqqqopoNEr79u2bu5VG47/NN9CmTZtIS0vjhz/8YZMdo6amhnA43GT7lyTV3+7du2ndunVztyFJzS4xMbG5W2h0PlbXADfddBN33HEH5eXlhEIhOnXqRF1dHUVFRXTu3JljjjmGnj178oc//CHYZs+ePeTm5gbzXbp04dFHH91nv1dccQW/+tWvSE9Pp0uXLt/1qUnSYWP+/PlccMEFtG/fng4dOnDppZeyadMmAD7++GNCoRAvv/wy/fv3Jz4+np49e1JSUhKzj2eeeYaMjAzi4+O58sormTp16j7/hfPVV1+lV69etGnThpNOOokJEyZQW1sbzIdCIZ588kkuu+wy2rZty69+9asmP3dJOhJ8/bG66upq7rzzTpKTk2nTpg0XXHABq1atAv7vdZRTTjmFhx56KGb70tJSQqEQGzdu/K5bPyDDUQM8+uijTJw4kRNOOIGtW7eyatUqioqKeOGFF3jqqadYv349Y8eO5YYbbmDJkiUA1NXVccIJJ/DSSy+xYcMGxo8fz89//nNefPHFmH0vWrSIsrIyiouLmTt3bnOcniQdFnbu3El+fj7vvvsuixYtokWLFlx55ZXU1dUFNf/v//0/7r77bkpLSzn11FMZNmxYEGyWL1/Obbfdxk9+8hNKS0u56KKL9gk2y5YtY8SIEfzkJz9hw4YN/Md//AczZszYp66wsJArr7yStWvXcvPNNzf9yUvSEebee+/lP//zP3n++ed57733OOWUU8jOzuaLL74gFApx880389xzz8Vs89xzz9G3b19OOeWUZup6P6JqkIcffjiamZkZjUaj0a+++ioaHx8fXbFiRUxNbm5udNiwYQfcR15eXnTo0KHB+siRI6MpKSnR6urqJulZko5kn332WRSIrl27Nrp58+YoEP3Nb34TzK9fvz4KRD/44INoNBqNXnvttdGcnJyYfQwfPjyamJgYrA8YMCD64IMPxtT89re/jaalpQXrQPSuu+5qgjOSpCPbyJEjo5dffnl0x44d0datW0dnzpwZzNXU1ETT09OjkydPjkaj0eh///d/R1u2bBlduXJlMN+xY8fojBkzmqX3A/HOUSPYuHEju3bt4qKLLuLYY48NlhdeeCF4BARg2rRp9O7dm+OPP55jjz2Wp59+mvLy8ph9de/e3feMJAn46KOPGDZsGCeddBIJCQl06tQJIOa62aNHj+DvtLQ0ALZt2wZAWVkZ5557bsw+/3H9/fffZ+LEiTHX7lGjRrF161Z27doV1J199tmNem6SdDTZtGkTu3fv5vzzzw/GWrduzbnnnssHH3wAQHp6Ojk5OUyfPh2A1157jerqaq655ppm6flA/CBDI9ixYwcA8+bN45/+6Z9i5uLi4gCYPXs2d999N7/+9a/JysqiXbt2TJkyhZUrV8bUt23b9rtpWpIOc0OGDCEzM5NnnnmG9PR06urqOOOMM6ipqQlqvv5hhFAoBBDz2N3B7NixgwkTJnDVVVftM9emTZvgb6/NkvTt3XLLLdx44408/PDDPPfcc1x77bXEx8c3d1sxDEeNoGvXrsTFxVFeXs6PfvSj/dYsX76cH/7wh/zrv/5rMPb1u0qSpL/7/PPPKSsr45lnnuHCCy8E4C9/+Uu99tGlS5fgZeC9/nG9V69elJWVHV7Pu0vSEebkk08mHA6zfPlyMjMzgf/7sueqVau46667grpLLrmEtm3b8uSTTzJ//nyWLl3aTB0fmOGoEbRr1467776bsWPHUldXxwUXXEBVVRXLly8nISGBkSNH8oMf/IAXXniBN998k86dO/Pb3/6WVatW0blz5+ZuX5IOO8cddxwdOnTg6aefJi0tjfLycn72s5/Vax933HEHffv2ZerUqQwZMoTFixfzxhtvBHeYAMaPH8+ll17KiSeeyNVXX02LFi14//33WbduHb/85S8b+7Qk6ajUtm1bbr/9du655x6SkpI48cQTmTx5Mrt27SI3Nzeoa9myJTfddBMFBQX84Ac/ICsrqxm73j/fOWokDzzwAL/4xS8oKiri9NNP5+KLL2bevHlB+Ln11lu56qqruPbaa+nTpw+ff/55zF0kSdLftWjRgtmzZ7N69WrOOOMMxo4dy5QpU+q1j/PPP5+nnnqKqVOn0rNnT+bPn8/YsWNjHpfLzs5m7ty5LFiwgHPOOYfzzjuPhx9+OPgvn5KkQzNp0iSGDh3KjTfeSK9evdi4cSNvvvkmxx13XExdbm4uNTU1/PjHP26mTr9ZKBqNRpu7CUmSvgujRo3iww8/ZNmyZc3diiQd8YYNG0bLli353e9+d8jbLFu2jAEDBrBlyxZSUlKasLuG8c6RJOmo9dBDD/H++++zceNGHn/8cZ5//nlGjhzZ3G1J0hGttraWDRs2UFJSQrdu3Q5pm+rqaj755BMKCwu55pprDstgBIYjSdJR7J133uGiiy6ie/fuPPXUUzz22GPccsstzd2WJB3R1q1bx9lnn023bt247bbbDmmb3//+92RmZrJ9+3YmT57cxB02nI/VSZIkSRLeOZIkSZIkwHAkSZIkSYDhSJIkSZIAw5EkSZIkAYYjSZIkSQIMR5IkSZIEGI4kSZIkCTAcSZIkSRIA/x9fZo2bk+c81gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4) )\n",
    "plt.hist(data[\"Emotion\"]  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7CB6fi9REYU"
   },
   "source": [
    "### remove special charchater , tags and covert emoji into emoji unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KWWV26wx-kZe"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "sents=[]\n",
    "for sent in data[\"Comment\"]:\n",
    "    sent = re.sub(r'' , \"\" , sent)\n",
    "    sent = re.sub(r'[^a-zA-Z0-9\\s]' , \"\" , sent)\n",
    "    sent = sent.lower()\n",
    "    sent = emoji.demojize(sent)\n",
    "    sents.append(sent)\n",
    "data['Comment'] = sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J5wU-kyrBvBG",
    "outputId": "46bc9adc-76c9-4764-829a-5b7e08c2a4e8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rahul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rahul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\rahul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nz2_FYQ0Q5OZ"
   },
   "source": [
    "###  lemmatization and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3ZGkyMJg-kb-"
   },
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words(\"english\"))\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "new_text_arr =[]\n",
    "corpus_for_word2vec = []\n",
    "for sent in data[\"Comment\"]:\n",
    "   text = word_tokenize(sent)\n",
    "   text =[lemmatizer.lemmatize(word) for word in text if word not in stopwords]\n",
    "   text = \" \".join(text)\n",
    "   new_text_arr.append(sent)\n",
    "   corpus_for_word2vec.append(text)\n",
    "\n",
    "data[\"Comment\"] = new_text_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "CC8BSetI-kea",
    "outputId": "a05ad8f7-ac26-4ec6-e6d4-f2cb59a7e7ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotion\n",
       "anger    2000\n",
       "joy      2000\n",
       "fear     1937\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "data[\"Emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uDzG0GjZ-kgx"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train ,y_test = train_test_split(data[[\"Comment\"]] , data[\"Emotion\"]  , test_size =0.3 , random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "waPtxsPP-kiv",
    "outputId": "9e521bab-bbf2-48c2-b330-0dae9c7dcede"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Label_encoder = LabelEncoder()\n",
    "Label_encoder.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QIPHhg2bCYqX"
   },
   "outputs": [],
   "source": [
    "y_train = Label_encoder.transform(y_train)\n",
    "y_test = Label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2zOx4WbQsoR"
   },
   "source": [
    "### TF_IDF (text to vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "GvCuYH9d-kk-",
    "outputId": "723cbbc2-c685-473f-b2e9-d531b85c4353"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_idf = TfidfVectorizer()\n",
    "tf_idf.fit(x_train[\"Comment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "w4LY_EQpCrO6"
   },
   "outputs": [],
   "source": [
    "x_train=tf_idf.transform(x_train[\"Comment\"]).toarray()\n",
    "x_test=tf_idf.transform(x_test['Comment']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tXNb5w0ZC9iP",
    "outputId": "eb8072a7-4432-4174-9aa0-747915decd87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4155, 7250)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=pd.DataFrame(x_train)\n",
    "x_test=pd.DataFrame(x_test)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8YehmaWRzjK"
   },
   "source": [
    "### support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "GFAEIq2iRs80",
    "outputId": "b325a7ce-4257-43b5-9db3-8483494fddf8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "piqXqETaSryC"
   },
   "outputs": [],
   "source": [
    "y_pred = svc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NvYWh3VVSw6P",
    "outputId": "2803ea74-c5d1-4fc4-baae-36ba27a07439"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score of svc :-  0.9001122334455668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(f\"accuracy_score of svc :-  {accuracy_score(y_test ,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(svc, x_train, y_train, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_accuracy = scores.mean()\n",
    "print(\"Mean Accuracy:\", mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T5BnTNjVQe9a"
   },
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "l_n-nb1fM54l",
    "outputId": "15d232aa-207f-42c3-eaf9-90266963f0cf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "RandomForest = RandomForestClassifier()\n",
    "RandomForest.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "o_XbC-9JQWs_"
   },
   "outputs": [],
   "source": [
    "y_pred = RandomForest.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYNE8z1zSLch",
    "outputId": "f08e78a1-31c6-43ee-d9fd-6d3c53e72f25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score of random forest :-  0.9102132435465768\n"
     ]
    }
   ],
   "source": [
    "print(f\"accuracy_score of random forest :-  {accuracy_score(y_test ,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score :-  0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "bst = XGBClassifier(n_estimators=130, max_depth=8 ,learning_rate=0.1, objective='multi:softmax')\n",
    "bst.fit(x_train, y_train)\n",
    "# make predictions\n",
    "preds = bst.predict(x_test)\n",
    "y_pred= bst.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"accuracy_score :- \" , accuracy_score(y_test ,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rahul\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.3410 - loss: 1.1013 - val_accuracy: 0.3369 - val_loss: 1.0989\n",
      "Epoch 2/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.3646 - loss: 1.0970 - val_accuracy: 0.3646 - val_loss: 1.0954\n",
      "Epoch 3/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.3442 - loss: 1.0929 - val_accuracy: 0.5187 - val_loss: 1.0728\n",
      "Epoch 4/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.4198 - loss: 1.0487 - val_accuracy: 0.7545 - val_loss: 0.9435\n",
      "Epoch 5/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.6027 - loss: 0.9166 - val_accuracy: 0.8123 - val_loss: 0.7097\n",
      "Epoch 6/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.7381 - loss: 0.6986 - val_accuracy: 0.8532 - val_loss: 0.5063\n",
      "Epoch 7/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8022 - loss: 0.5360 - val_accuracy: 0.8809 - val_loss: 0.4039\n",
      "Epoch 8/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8635 - loss: 0.4335 - val_accuracy: 0.9013 - val_loss: 0.3625\n",
      "Epoch 9/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8974 - loss: 0.3619 - val_accuracy: 0.8917 - val_loss: 0.3534\n",
      "Epoch 10/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9078 - loss: 0.2998 - val_accuracy: 0.8905 - val_loss: 0.3541\n",
      "Epoch 11/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9253 - loss: 0.2799 - val_accuracy: 0.8869 - val_loss: 0.3545\n",
      "Epoch 12/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9234 - loss: 0.2384 - val_accuracy: 0.8929 - val_loss: 0.3780\n",
      "Epoch 13/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9445 - loss: 0.1869 - val_accuracy: 0.8977 - val_loss: 0.3823\n",
      "Epoch 14/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9428 - loss: 0.1898 - val_accuracy: 0.9001 - val_loss: 0.3747\n",
      "Epoch 15/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9506 - loss: 0.1778 - val_accuracy: 0.9025 - val_loss: 0.3968\n",
      "Epoch 16/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9610 - loss: 0.1290 - val_accuracy: 0.8977 - val_loss: 0.4764\n",
      "Epoch 17/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9568 - loss: 0.1394 - val_accuracy: 0.8917 - val_loss: 0.4848\n",
      "Epoch 18/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.9653 - loss: 0.1362 - val_accuracy: 0.8977 - val_loss: 0.4708\n",
      "Epoch 19/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9643 - loss: 0.1205 - val_accuracy: 0.8905 - val_loss: 0.4769\n",
      "Epoch 20/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9520 - loss: 0.1484 - val_accuracy: 0.8833 - val_loss: 0.5567\n",
      "Epoch 21/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9593 - loss: 0.1203 - val_accuracy: 0.8953 - val_loss: 0.4919\n",
      "Epoch 22/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.9636 - loss: 0.1281 - val_accuracy: 0.8929 - val_loss: 0.5517\n",
      "Epoch 23/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9591 - loss: 0.1287 - val_accuracy: 0.8917 - val_loss: 0.5826\n",
      "Epoch 24/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9636 - loss: 0.1233 - val_accuracy: 0.8953 - val_loss: 0.5252\n",
      "Epoch 25/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9606 - loss: 0.1124 - val_accuracy: 0.8929 - val_loss: 0.6047\n",
      "Epoch 26/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9702 - loss: 0.0930 - val_accuracy: 0.8965 - val_loss: 0.6184\n",
      "Epoch 27/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9685 - loss: 0.1017 - val_accuracy: 0.8833 - val_loss: 0.7454\n",
      "Epoch 28/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9716 - loss: 0.1057 - val_accuracy: 0.8989 - val_loss: 0.6406\n",
      "Epoch 29/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9765 - loss: 0.0723 - val_accuracy: 0.9061 - val_loss: 0.6339\n",
      "Epoch 30/30\n",
      "\u001b[1m333/333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9686 - loss: 0.0897 - val_accuracy: 0.9001 - val_loss: 0.7198\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9042 - loss: 0.5926\n",
      "Test Loss: 0.5859761834144592\n",
      "Test Accuracy: 0.898428738117218\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, input_dim=x_train.shape[1], activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dropout(0.7),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=30, batch_size=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Convert Text to Vector using Word2vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(model[sent], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Apply average Word2Vec embedding to each sentence in corpus\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m vector_corpus \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mapply_avg2wordvec\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcorpus_for_word2vec\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Convert the list of vectors to numpy array\u001b[39;00m\n\u001b[0;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(vector_corpus)\n",
      "Cell \u001b[1;32mIn[40], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(model[sent], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Apply average Word2Vec embedding to each sentence in corpus\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m vector_corpus \u001b[38;5;241m=\u001b[39m [\u001b[43mapply_avg2wordvec\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m corpus_for_word2vec]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Convert the list of vectors to numpy array\u001b[39;00m\n\u001b[0;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(vector_corpus)\n",
      "Cell \u001b[1;32mIn[40], line 7\u001b[0m, in \u001b[0;36mapply_avg2wordvec\u001b[1;34m(sent)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_avg2wordvec\u001b[39m(sent):\n\u001b[1;32m----> 7\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_to_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sent:  \u001b[38;5;66;03m# Check if sent is empty after filtering\u001b[39;00m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(model\u001b[38;5;241m.\u001b[39mvector_size)  \u001b[38;5;66;03m# Return zero vector if sent is empty\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[40], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_avg2wordvec\u001b[39m(sent):\n\u001b[1;32m----> 7\u001b[0m     sent \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sent \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mindex_to_key]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sent:  \u001b[38;5;66;03m# Check if sent is empty after filtering\u001b[39;00m\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(model\u001b[38;5;241m.\u001b[39mvector_size)  \u001b[38;5;66;03m# Return zero vector if sent is empty\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "model = api.load('word2vec-google-news-300')\n",
    "\n",
    "# Define a function to apply average Word2Vec embedding\n",
    "def apply_avg2wordvec(sent):\n",
    "    sent = [word for word in sent if word in model.index_to_key]\n",
    "    if not sent:  # Check if sent is empty after filtering\n",
    "        return np.zeros(model.vector_size)  # Return zero vector if sent is empty\n",
    "    else:\n",
    "        return np.mean(model[sent], axis=0)\n",
    "\n",
    "# Apply average Word2Vec embedding to each sentence in corpus\n",
    "vector_corpus = [apply_avg2wordvec(s) for s in corpus_for_word2vec]\n",
    "\n",
    "# Convert the list of vectors to numpy array\n",
    "x = np.array(vector_corpus)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, df[\"Liked\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=110)\n",
    "rfc.fit(x_train , y_train)\n",
    "y_pred = rfc.predict(x_test)\n",
    "print(f\"accuracy_score {accuracy_score(y_test ,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train , y_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "print(f\"accuracy_score {accuracy_score(y_test ,y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
